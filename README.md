# search_engine
🔍基于RSS的全文搜索引擎

## 遇到的问题
### 1. vector在删除元素之后的迭代器失效
```c++
std::vector<std::string> wordList = SplitToolCppJieba::GetInstance()->cut(str);
for (auto it = wordList.begin(); it != wordList.end();)
{
    if (stopWordList.find(*it) != stopWordList.end())
    {
        wordList.erase(it);
    }
    else // 没有删除元素才让迭代器向后移动
    {
        ++it;
    }
}
```

### 2. 对两个数据结构求并集
```c++
std::vector<int> vec1 = {1, 2, 3, 4, 5};
std::vector<int> vec2 = {3, 4, 5, 6, 7};
std::vector<int> intersection;

// 计算交集
std::set_intersection(vec1.begin(), vec1.end(), vec2.begin(), vec2.end(), std::back_inserter(intersection));

// std::back_inserter 是一个标准库函数，它返回一个插入迭代器，该迭代器使用容器的 push_back 成员函数在容器的末尾插入元素。它通常用于算法函数中，以便将结果插入到容器的末尾，而不是覆盖现有的元素。
```

## 缓存系统
### 1. 引入缓存的目的
引入缓存的目的：为了减少读取磁盘（查询数据库）的次数，根据局部性原理，在内存中创建一个数据结构，保存临时、热点查询词的结果

### 2. 缓存的数据结构
`unordered_map<string, string(json)>`：<查询词，查询结果>（淘汰）

### 3. 缓存的淘汰策略
假设缓存的上限只能有1000条，新的缓存数据到来就会发生缓存淘汰
三种淘汰策略：
1. FIFO：先进先出，但新的数据可能不是热点词，但它需要很久才被淘汰
2. LFU：根据频率
3. LRU：最近最少使用，LRU使用体验和LFU差不多，但性能好得多。
需要一个数据结构做存储，方便进行中间删除：`list<pair<key, json>>`，热点数据放头部，冷数据放尾部
一个数据结构做索引：方便进行查找，：`unordered_map<key, iterator>`，查得到key就根据迭代器去list中查找，查不到就去磁盘找

### 4. 缓存的并发问题
从业务上来说，缓存需要多用户共享，多用户就意味着多线程，多线程共享缓存就意味着竞争条件==》加锁，但如果缓存没有命中，就需要去读取磁盘，这样加锁的时间就会长
优化方向：
1. 每个线程一个缓存，各个缓存是独立的，工作线程只能看到自己的缓存，防止死锁。
2. 不应该让工作线程去处理缓存的更新：1. 设计上做解耦，不能让工作线程既要处理业务，又要管架构；2. 技术上避免死锁
3. 缓存管理线程：1. 更新保证缓存的一致性，2. 定时（一开始更新快一点，后面更新慢一点）

### 5. 缓存管理线程，怎样更新
1. 从所有的缓存中随机挑选一个主节点
2. 将所有从节点的修改发给主节点（取并集）
3. 主节点广播
4. 注意：主节点一直加锁，从节点发送时和接收广播时加锁

### 6. 增量更新策略
目的：减少锁从节点的时间，更新的速度快了一丢丢
做法：每个缓存另外开辟一个数据结构，记录自上次更新以后所有的修改，这样每个数据要保存两遍
数据结构：`list<string, string>`

### 7. 读写分离更新策略
每个线程管理两个缓存，

### 8. 代码上要注意的事情
1. 不适合将Cache类作为Thread类的数据成员
2. 单独一个单例CahcheManage管理所有的缓存
3. 缓存使用vector<Chache>，比map通用性好

### 9. 线程局部存储 thread_local
